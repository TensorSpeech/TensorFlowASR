# Copyright 2020 Huy Le Nguyen (@usimarit)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

speech_config:
  sample_rate: 16000
  frame_ms: 25
  stride_ms: 10
  num_feature_bins: 80
  feature_type: log_mel_spectrogram
  preemphasis: 0.97
  normalize_signal: True
  normalize_feature: True
  normalize_per_frame: False

decoder_config:
  vocabulary: null
  target_vocab_size: 1024
  max_subword_length: 4
  blank_at_zero: True
  beam_width: 5
  norm_score: True

model_config:
  name: streaming_transducer
  encoder_reductions:
    0: 3
    1: 2
  encoder_dmodel: 320
  encoder_rnn_type: lstm
  encoder_rnn_units: 1024
  encoder_nlayers: 2
  encoder_layer_norm: True
  prediction_embed_dim: 320
  prediction_embed_dropout: 0.0
  prediction_num_rnns: 2
  prediction_rnn_units: 1024
  prediction_rnn_type: lstm
  prediction_projection_units: 320
  prediction_layer_norm: True
  joint_dim: 320
  joint_activation: tanh

learning_config:
  augmentations:
    feature_augment:
      time_masking:
        num_masks: 10
        mask_factor: 100
        p_upperbound: 0.05
      freq_masking:
        num_masks: 1
        mask_factor: 27

  dataset_config:
    train_paths:
      - /mnt/Miscellanea/Datasets/Speech/LibriSpeech/train-clean-100/transcripts.tsv
    eval_paths:
      - /mnt/Miscellanea/Datasets/Speech/LibriSpeech/dev-clean/transcripts.tsv
      - /mnt/Miscellanea/Datasets/Speech/LibriSpeech/dev-other/transcripts.tsv
    test_paths:
      - /mnt/Miscellanea/Datasets/Speech/LibriSpeech/test-clean/transcripts.tsv
    tfrecords_dir: null

  optimizer_config:
    class_name: adam
    config:
      learning_rate: 0.0001

  running_config:
    batch_size: 2
    accumulation_steps: 1
    num_epochs: 20
    outdir: /mnt/Miscellanea/Models/local/streaming_transducer
    log_interval_steps: 300
    eval_interval_steps: 500
    save_interval_steps: 1000
